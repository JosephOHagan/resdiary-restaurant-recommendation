% This example An LaTeX document showing how to use the l3proj class to
% write your report. Use pdflatex and bibtex to process the file, creating 
% a PDF file as output (there is no need to use dvips when using pdflatex).
% Modified 

% This dissertation was built upon base template provided.

\documentclass{l3proj}

\begin{document}

\title{Team I: ResDiary Restaurant Recommendation System}

\author{Vladimir Bardarski \\
        Paulius Dilkas \\
        Domantas Jurkus \\
        Eduard Kalfov \\
        Josh O'Brien \\
		Joseph O'Hagan}

\date{31st March 2017}

\maketitle

% ##################################################
% LAST EDIT: 	27/03/17	Josh
% ################# Comment Log ####################
% Josh: Note: what we DISCOVERED as opposed to what we did, but also need to talk about results. 
% Looked at various academic papers for ideas. 
% ##################################################
\begin{abstract}
Recommendation systems are increasingly used by businesses to provide their customers with tailored suggestions for products that may interest them. This paper presents a case study of the challenges we encountered in developing such a system for a well-known restaurant booking service. 

We discuss how we implemented and delivered a working recommendation engine which produces sensible suggestions for new restaurants, tailored to a given user's taste. We explore the relevant machine learning concepts we discovered and the technologies we utilised. Finally, we reflect on the software engineering practices we followed throughout the project and how they contributed to the end result.
\end{abstract}

%\begin{itemize}
%\item The abstract is likely the first substantive description of your work read by an examiner. View it as an opportunity to set accurate expectations.
%\item The abstract is a summary of the whole thesis. It presents all the major elements of your work in a highly condensed form. (Write it having written the rest of the paper) The paper sets the abstract.
%\item It must be capable of substituting for the whole paper when there is insufficient time and space for the full text.
%\item Keep it short and snappy. 
%\item The primary function of your thesis (and by extension your abstract) is not to tell readers what you did, it is to tell them what you discovered.
%\item Approximately the last half of the abstract should be dedicated to summarizing and interpreting your results.
%\item The most common error in abstracts is failure to present results.
%\end{itemize}

% Comment out this line if you do not wish to give consent for your work to be distributed in electronic format.
\educationalconsent
\newpage

%==============================================================================

% ##################################################
% LAST EDIT: 	06/03/17	Josh
% ################# Comment Log ####################
% [A] "subsequent sections..." or "subsequent Sections..."
% ##################################################
\section{Introduction}
\label{sec:intro}
% An introduction, explaining the purpose of the document, a very brief outline of the project and a summary of the structure of the rest of the document (approximately 1-2 pages).

The Professional Software Development (PSD3) course at The University of Glasgow requires students to engage with the practices and methodologies used in modern large-scale software engineering. The purpose of this dissertation is to document the development of the software project created as part of this course by Team I. 

The project was to build, over the course of several months, a recommendation engine for the Glasgow-based company ResDiary.
The main deliverable was a system capable of producing sensible restaurant recommendations for existing ResDiary users; a system that could be integrated into the existing ResDiary platform at a later date. 

Our team consisted of six third-year Computing Science students. Within the group there was a broad range of skills, interests and experience - with two members actively working as software professionals, and another having participated in an internship. For some members, however, this was a first opportunity to interact with a real client. 

In this document we outline, in detail, the entire process: from the initial requirements gathering with our customer, through to final system delivery. 

In section \ref{sec:background} we present the background to the project, the motivations of the customer and how we arrived at the agreed deliverables.

%this will surely be expanded to enumerate each separate section better I would like to discuss in detail the practices, issue-tracking, the team work/team load - Josh etc.

% [A]
In subsequent sections \ref{sec:leadreflection} through Section \ref{sec:droppingreflection} we explore the challenges we faced through development and the steps we took to resolve them, explore the impact of team dynamics on the outcome and reflect on what we have learned from the experience. We also explain how we applied the good development practices learned in PSD3. In particular we highlight the role of version control, agile development and issue tracking.

\newpage

%==============================================================================

\section{Case Study Background}
\label{sec:background}
% A description of the case study background and context. This should include a description of the project customer (what was the nature of the organisation you were working for), their objectives for the project, and a summary of what was actually achieved. Where appropriate, this section should also make reference to similar related projects in order to make the context clear (approximately 4-5 pages).

% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

% Section 2 needs to be trimmed. 
% That means either reducing Sections 2.2, 2.4, 2.5 (I think the rest are fine) or pulling stuff out and maybe making a reflection point on incorporating user feedback. 
% I'm not entirely sure which - perhaps get others (Dom, Paulius, etc.) to suggest which would flow better

% Additionally ask others for referencing -- I'm sure Paulius would have the better selection for Model / system design section
% Perhaps more case study style of references are needed, i.e. (the team was a aware of the risks assoicated with X as highlighted by REFERENCE)
% Another form of referencing could be: one improvement to the team's development process would be the introduction of technique Y as outlined REFERENCE

% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

\subsection{Customer}
\label{sec:customer}
% ##################################################
% LAST EDIT: 	18/03/17	Josh
% ################# Comment Log ####################
% ##################################################

% The customer organisation and background.

% Who are ResDiary?
ResDiary are a Glasgow-based online restaurant reservation service; a commercial organisation providing a comprehensive, easy to use booking and table management platform for use by the hospitality industry. The company provides 24-hour reservation services through both social media and their own booking portal ResDiary.com. Diners can browse restaurants, book tables and place reviews. Restaurants can access tools which let them optimize their yields, manage their reservations and attract new diners. Their global service sees 9.7 million bookings every month, and their platform is used by over 6,500 restaurants across 58 countries. 

ResDiary senior software engineers Adam Connelly and Ian Strachan acted as customer representatives throughout the duration of the development. They helped us understand the company line-of-thought behind the project, in addition to providing useful feedback, answering queries and supplying the team with the anonymised ResDiary booking data we required.


\subsection{Customer Objectives And Rationale}
\label{sec:custobjectives}
% ##################################################
% LAST EDIT: 	23/03/17    Joseph
% NOTE: 		Reference papers on Amazon / Netflix Models / Netflix Prize
% NOTE:         Added more specifics on Netflix Recommendations - make sure to tie in to our final output
%               Need to demonstrate that the research was RELEVANT
% ################# Comment Log ####################
% [A] -- "As such, therefore,..." -- Reads a little strange
% ##################################################

% The rationale and initial objectives for the project.

% Initial Meeting and the customer's motivation for the project.

The initial customer meeting occurred on October 19th and was led by Ian Strachan. This was our first contact with the customer and served as the customer requirements elicitation meeting. The meeting began with an overview of the ResDairy business, a discussion of the services they provide and an explanation of their technology stack. The ResDiary daily operation involves gathering large quantities of valuable customer data. This collection of big data, however, is currently unused beyond supporting basic business needs (i.e. retrieving booking records). The developers view this as a significant shortcoming of their system.

As such, the company is exploring potential ways to exploit this vast quantity of valuable data. The developers had conducted some research into the area, and discovered that none of their competitors currently offer a restaurant recommendation service within their booking platform. Thus, if they were able to develop a system which would make recommendations to users based on their previous dining habits and similarity to other users, they would gain a competitive edge. It would also help increase restaurant discovery on their platform, which is beneficial to both restaurants and potential clientele. 

The inspiration for the idea stems from the similar system provided by online services such as Amazon and Netflix, which push recommended products and films respectively to their users. The Netflix model, in particular, was the closest reference point for the system they wished to develop. A parallel between making recommendations based on a user's film history and their similarity to other users, and a similar recommendation engine using ResDiary's dining history is easy to see. As a starting point for our own research, they suggested looking into the Netflix Prize - a competition held by Netflix starting in 2006 challenging participants to better their own recommendation algorithm \cite{NetflixPrize}. This investigation proved extremely valuable in guiding our eventual design. We discuss our findings from the research in Section \ref{sec:modelreflection}.

We also spent time discussing what the customer viewed as the end state of the system - whether it would be integrated into the existing ResDiary portal or whether the output would suffice as a proof-of-concept prototype. They were initially undecided in this regard, partially due to an internal transition in their own development framework, and thus suggested our initial aim should be to focus on the creation of the recommendation engine. The decision regarding the final state of the project would ultimately not be made until midway through the development cycle when the customer decided to view the project as simply a proof-of-concept. Nonetheless, at all points during development, due consideration was given to the future integration of our system with ResDiary's own. 


\subsection{Project Scoping}
\label{sec:ourinitobjectives}
% ##################################################
% LAST EDIT:  18/03/17  Josh
% NOTE:         JOSH: Expanded on importance of requirements.
% NOTE:         References: importance of requirements gathering, cost of making corrections 
% ################# Comment Log ####################
%
% ##################################################

The risks and costs associated with a project of this nature demand thorough background investigation and cogent planning before development proper commences. The cost of correcting errors grows enormously in the latter stages of a software project \cite{SoftwareErrorAnalysis}.

Our first major task was to formalise our discussions with the client and produce a requirements specification to serve as a project proposal document. The goal was to have a clear outline of the scope of the project and a set of deliverables to present to the client at the next meeting on November 16th. Our requirements gathering occurred in tandem with conducting the necessary initial background research on machine learning and recommendation systems. 

The proposal document included an array of requirements that the team agreed upon, based on our interpretation of the customer's initial project pitch. It was important that our requirements were reasonably comprehensive and realistic, but we accepted that they would be continually revised and refined as the project developed. 

\subsubsection{Initial functional requirements:}
\begin{itemize}
\item The recommendation engine must accurately suggest restaurants based on the users' dining history and similarity to other users with similar eating preferences.
\item Recommended restaurants should be in close proximity to where the user typically eats or the geographical location of where they are currently searching.
\item The recommendation engine may recommend restaurants that the user has previously visited should the user allow this option.
\end{itemize}

\subsubsection{Initial nonfunctional requirements:}
\begin{itemize}
\item The engine should be written to allow for easy integration into the existing ResDiary system.
\item The system should give a response within one second after receiving the request (provided data is stored locally).
\item New users should be presented an optional quick questionnaire to gather initial data.
\item User and restaurant locations should be interpreted using coordinates rather than city name as those are of arbitrary precision within the dataset.
\end{itemize}

To help us understand the actual scenarios in which the system might be used, we prepared a set of user stories (ranked by priority). They provided a quick, intuitive way to ensure we had covered all the conceivable use cases the customer may require.
%We also prepared a high-level system UML diagram and a step-by-step work-flow of how the system would generate the actual recommendations.
Due to the customer's ambiguity regarding the final state of the system, the endpoint was left intentionally vague to allow for flexibility. Instead the emphasis was to build and produce the most accurate recommendation for a given user. 


\subsection{Refinement of Requirements}
\label{sec:custrefineinitobj}
% ##################################################
% LAST EDIT:  30/03/17 JOSH
% ################# Comment Log ####################
% If required (page count) maybe cut down requirements engineering and incorporating customer feedback in reflection point
% ##################################################

At the November 16th meeting we presented and discussed our project proposal with the customer. They broadly agreed with the proposed requirements and could envision how our high level system would operate (and potentially integrate into their existing one). We briefly explained that there were two major models for building recommendation systems: collaborative-based filtering (similarity between users) and content-based filtering (building a profile of a user and matching them to relevant items). 

The high level system architecture accounts for this by allowing multiple `recommenders' to each implement a different approach to producing recommendations (see Figure \ref{fig:uml}). 
These recommendations are then combined and filtered for the final output by a `system recommender'. An evaluator component measures the accuracy of the generated recommendations. The customer expressed strong interest in the potential of `fine tuning' this system, through altering the significance placed on individual recommenders. 

\begin{figure}[ht]
\centering
\includegraphics[width=8cm]{images/ResDiary_UML.png}
\caption{High level system architecture showing multiple recommenders and the evaluator.}
\label{fig:uml}
\end{figure}

There were, of course, areas of concern. Our proposed response rate of one second to respond to a request was queried. They felt that they needed to further clarify the volume of data the system would be expected to work with in a real world deployment. This may put a constraint on our ability to realise that performance. We discussed the alternative of using a nightly build system, as this was how they expected the system would operate in a real world setting. In addition, they proposed developing a lightweight front-end application to display the recommendations. This would be a lightweight app, rather than any actual integration with their system, but they rationalised its throwaway nature by suggesting it would help them better understand our system, assist with demonstrating its functionality and most importantly provide a clear indication it was producing sensible results. 

We made modifications to the specification document to incorporate the customer feedback. In particular, the team felt the need to revise the non-functional requirements of the project. The disputed "one second local response rate" requirement was rescinded and in its place we inserted two new requirements:

\begin{itemize}
\item Provided the data is not stored locally, the system should be set up to allow for nightly updates to the recommendations.
\item Have the ability to “fine tune” the recommendation engine by altering the weighting significance of different components of the recommendation such as distance, price, 
reviews, etc.
\end{itemize}

Furthermore, a soft goal developed within the team to produce a more comprehensive front end application to showcase the recommendation system. While some members felt this justified being included and defined formally within the specification, the majority felt the focus of the project should be on creating the most accurate recommendations.

Initial development efforts were split between the creation of a prototype system (which implemented a basic content-based filtering model) and on the long-term solution (with multiple recommenders) to the project. The prototype system was demonstrated during an interim meeting on December 7th, where the technical decisions of the long term solution were discussed at length. Following this meeting, the full implementation of the system commenced. 

\subsection{Defining the End Product}
\label{sec:jandefinedstate}
% ##################################################
% LAST EDIT:  15/03/17  Joseph
% NOTE:         Needs reworking
% NOTE:			Needs referencing
% ################# Comment Log ####################
% ##################################################

As we discuss in the previous sections, the decision to define an exact final handover state for the system was deferred until the end of the third development sprint. During our January 26th progress meeting, the team pressed the customer for clarity on how they envisioned the end product. 

It became clear that the customer wished to view the project as a `proof-of-concept' demonstration, with their intended use being to assess the worth of creating a similar system for their existing portal. Additionally, they wished to learn from our work, as both developers had little experience in the field of machine learning.

With the final handover state of the system now clarified, the team decided that a redesign of the front-end of the application was necessary. We noted while giving a demonstration of the software to a non-technical member of the ResDiary team, that the system was not properly communicating the recommendations being made. It was unclear to a non-technical user how the system operated and whether or not the results it produced were sensible. Given it was confirmed that the primary audience of our software will likely be non-technical users (being given a demonstration), there was a necessity to produce a more intuitive, friendly front end. 

The following requirements were discovered and added to the project, with the aim of producing a front-end redesign which visually demonstrated that the system was producing accurate predictions:

Functional
\begin{itemize}
\item The front-end should display recommendations for a random pool of users to simulate typical use of the system.
\end{itemize}

Nonfunctional
\begin{itemize}
\item The front-end be designed such that it is aesthetically clear that the recommendations made are sensible and accurate.
\end{itemize}

%Ensure a reference is provided to feature removal
We also elected in the aftermath of the meeting to drop the proposed nonfunctional requirement of implementing recommendations for new users. A detailed justification of this decision can be found in Section \ref{sec:droppingreflection}.

\subsection{Delivered Software}
\label{sec:finsoftware}
% ##################################################
% LAST EDIT: 	28/03/17	Josh
% ################# Comment Log ####################
% Josh: possibly mention Netflix. Section 2 needs to be shorter in general. 
% ##################################################

% Information on the final software that was delivered to the customer.
At the final client meeting we delivered the completed software. The key features that were successfully implemented were:

\begin{itemize}
\item A working recommendation engine that produces sensible restaurant suggestions. 
\item An explicit collaborative filter recommender which uses ResDiary user ratings.
\item An implicit collaborative filter recommender which infers user ratings.
\item Content-based recommenders using restaurant cuisine type and price point.
\item A system recommender which combines the output from the different recommenders and selects the optimal recommendations.
\item An evaluator system which assesses the quality of the generated recommendations.
\item Recommendations filtered by location. 
\item A front-end application which allows the customer to select a random user and view their browsing history and our recommendations.
\end{itemize}

Both the team and the customer were satisfied with the end product. Our research into machine learning allowed us to understand how recommendation systems are built. We investigated different tools and frameworks for building our software, and selected a platform (Apache Spark) which suited our needs. This knowledge enabled us to construct a functional recommendation engine and implement a solution which meets the goals established at the outset of the project. 

% Dom: commented out for trimming Section 2
%Additionally, while our software uses csv files as its output, it can be easily configured to work with a database, and adapted with API calls to allow integration with the customer system. Future extensions to the system we discussed include providing a reasoning for recommendations (e.g. `This was recommended because the price is similar'), adapting the implicit collaborative filtering model to better work with the limits of the data (we discuss this in Section \ref{sec:modelreflection} and building a content-based recommender for location.

%==============================================================================
\section{Reflections}
\label{sec:reflections}
% ##################################################
% LAST EDIT: 	14/03/17	Joseph
% NOTE:	Currently misc. thoughts / notes
% ################# Comment Log ####################
% ##################################################

% Several sections that reflect on your experiences during the team project. Each section should discuss one theme, characterised by incidents or events that occurred during the team course of the project from which you learned (approximately 12-15 pages).


\subsection{Introduction}
\label{sec:leadreflection}
% ##################################################
% LAST EDIT:  27/03/17  Josh
% NOTE:      
% ################# Comment Log ####################
% ##################################################

% ################# References #####################
%
% https://www.cs.uic.edu/~liub/KDD-cup-2007/NetflixPrize-description.pdf  -- Netflix Prize Overview / Description Paper
% http://www.netflixprize.com/community/topic_1537.html  -- Links papers which build off each other (winners)
% 
% Collaborative & Content Based
% https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E6%8E%A8%E8%8D%90/papers/Large-scale%20Parallel%20Collaborative%20Filtering%20the%20Netflix%20Prize.pdf  -- Collaborative Filtering for the Netflix Prize
% http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf  -- Netflix Prize and SVD
%
% http://infolab.stanford.edu/~ullman/mmds/ch9.pdf  -- Content & Collaborative (Reommendation Systems Chapter of Stanford's MMDS and Automata Online Course) 
%
% May be best to ask Paulius & Eduard for some specifics on choice of models, etc.
% ##################################################

Throughout the development of the software project the team faced many challenges. Machine learning and ‘big data’ was an area in which most members of the team were inexperienced, and this was the first large software project the majority had participated in. In this section we discuss the significant decisions we made throughout the software process and reflect on where our approach was successful and the areas in which we identified shortcomings. 

We start by exploring the early technical choices. One must consider whether the major decisions in system design, technology stack and language choice were, in the final analysis, the optimal ones (\ref{sec:pyreflection}). We also consider the issue of whether there was sufficient and correct testing carried out and assess the difficulties in developing suitable tests for a machine learning application (\ref{sec:testing}).

We then analyse key elements of our software process: team structure and how it developed over time (\ref{sec:teamstructure}), how we managed intra-team communication  (\ref{sec:communication}), code reviews (\ref{sec:codereviewbranch}) and our use of pair programming (\ref{sec:pairprogramming}). Finally we discuss why certain features were dropped and our approach to cost estimation (\ref{sec:droppingreflection}).

\subsection{Reflection: Recommendation System Models}
\label{sec:modelreflection}
% ##################################################
% LAST EDIT:  27/03/17  Josh
% NOTE:         Temp notes / thoughts
% ################# Comment Log ####################
% ##################################################
% Josh: I moved the Netflix discussion here. Explain CF and CB. 
%  Considered explaining over-fitting and ALS in more detail, but trying to tie it to most relevant customer issues (i.e. lack of data)
%  I need to add some stuff on content-based and possibly expand on the evaluator, but again trying to keep it more geared towards process and reflection.
% ################# References #####################
% Section 3.3 ALS:  http://cs229.stanford.edu/proj2014/Christopher%20Aberger,%20Recommender.pdf
% Implicit ALS: http://yifanhu.net/PUB/cf.pdf
% ##################################################

There are two broad approaches to building recommender systems: \textbf{collaborative filtering} and \textbf{content-based filtering}. 

Collaborative-filtering algorithms work on the principle of identifying users with similar preferences (often obtained via user ratings), and recommending new items based on those preferences. It does not rely on specific information about the user nor the items under consideration, merely who the user is and the ratings they have given. Content-based filtering, by contrast, exploits the underlying features of items with which a user has previously interacted (bought or liked, depending on the context), and attempts to recommend items with similar features. These features may be descriptors such as film length or price. Hybrid recommenders combine both approaches to produce recommendations. Most of our development effort was concentrated on building a collaborative-filtering recommender, though we did implement content-based recommenders and a `system' recommender which combines recommendations from the other recommenders and outputs the best ones. 

As we outlined in our discussion of the customer’s initial motivation (\ref{sec:custobjectives}), the starting point of our research was investigating a challenge issued by Netflix in 2006 \cite{NetflixPrize}. Participants were tasked with developing a recommendation algorithm that would better their own. The goal of the algorithm was to accurately predict a user's rating of a film based solely on previous user ratings and no additional information about either the users or films. Naturally, this suggests a collaborative-filtering model.

A set of training data (a subset of Netflix's real user data) with half a million user ratings was provided to participants, with the candidate algorithm analysing this data and using it to predict user ratings for a second, disjoint subset of the user data (validation set). No information other than user ID, film ID and date of rating was provided. Our ResDiary project followed a similar structure. ResDiary's users, as with Netflix's, leave review scores ranging from 1 to 5. We were given a subset of their user data which we split into further subsets for training and for evaluation. The research thus provided an excellent springboard from which to launch our own collaborative filtering model. With such a strong similarity between the requirements of our system and theirs, it was a natural jump.

Our collaborative-filtering system used the well-known alternating least squares algorithm (ALS) \cite{ALS} to produce its results. Much of the challenge in implementing the model was in avoiding common machine learning pitfalls such as \textbf{overfitting} - an issue that occurs when the candidate model becomes too dependent on training data and performs poorly when predicting on new data. Ultimately our model produced credible results which the customer was impressed with, but the development was not without problems. A well-documented \cite{CollabFilter} difficulty of collaborative filtering is the sparsity of user ratings in most data, that is: most users simply \textit{do not rate} items they view or purchase. Certainly, we found with the ResDiary data set that many bookings had NULL entries for user ratings. We were able to overcome this, to some extent, by implementing an implicit ALS algorithm as an alternative recommender. Implicit algorithms infer a user rating where it does not exist by analysing other available properties \cite{ImplicitALS}. Our algorithm analyses the number of visits a user has made to a restaurant to imply a user preference.

One of the persistent issues that surfaced across many iterations was a lack of data. On multiple occasions we found that we simply did not possess the necessary volume of data to make our recommendations more accurate. Big data analysis, as the name implies, requires large quantities of data! Understandably, ResDiary could not give us access to real user data, given the associated data protection issues \cite{DataProtection}, but the volume of data we were given in the initial stages (around ten thousand rows), was a limiting factor in our early development efforts and compromised the extent to which we could fine-tune our end product algorithms. Before taking on a future project we may wish to clarify up front that large quantities of data will be required to produce meaningful results.

\subsection{Reflection: Technology}
\label{sec:pyreflection}
% ##################################################
% LAST EDIT:  30/03/17 JOSH
% NOTE:       I wonder if Technology Stack will just become one section. 
% ################# Comment Log ####################

% ################# References #####################
% http://accord-framework.net/ -- Accord.NET
% http://spark.apache.org/mllib/ -- SPARK MLib
% ##################################################

One of the key considerations in any software development project is the choice of the technologies used to implement it. We spent much of the first iteration contesting two broad approaches: implementing the system in their own language (C\#) or using our Python alternative.

From an early stage, as we outline in section 2, it was clear the client placed a high priority on integration with their existing system. In other words: with their existing technology stack. ResDiary uses Microsoft's C\# language and the ASP.NET web framework for its backend system. The natural starting point, therefore, was to find a solution within that language ecosystem. 

It became clear very quickly that in order to meet the goal of delivering a recommendation system within the time limit, we would be compelled to draw on existing machine learning libraries. It was not practical, nor within the team’s competency to write complex big data algorithms from scratch. The team researched machine learning libraries in C\# and found some promising results - the popular Accord.NET library providing much of the required functionality. 

In the end, after thorough discussion with the client, it was decided that Python would be used for building the system. Python is the industry standard for machine learning projects and had a lot of pre-existing libraries the team could utilise during development. Its natural application domain is scripting and data analysis. By contrast, though it does have some suitable libraries, C\# is geared towards web applications. Python also had the advantage of being familiar to the team, with the majority of members having at least two years development experience. By contrast, only one member had significant experience with C\# and the ASP.NET framework.

We made the decision to use the open source Apache Spark library. Spark provides a suite of tools for big data processing and machine learning (MLib), and exposes its functionality through APIs for Python. The key rationale for utilising Spark versus other potential libraries was its horizontal scalability. Spark is designed with clustered computing in mind allowing it to run its operations with high degree of parallelism. It also allows capacity to be dynamically increased as required.

Of course, the choice of Python as the implementation language begs the question of how we integrate with the customer system. After some research the team discovered that calling Python scripts from C\# would not be an issue.
To make integration easy, The team decided that a command-line interface for our project would be most suitable, making it entirely possible to invoke the recommendations system from the existing Resdiary codebase. After these considerations were brought to the client, a green flag was given for Python.
% ...the client did not have much familiarity with Python and that may have deterred them from wishing to use our system as more than a proof-of-concept ultimately. %The choice of language, perhaps, should have been discussed more thoroughly in the initial stages of the project.

\subsection{Reflection: Testing and Continuous Integration}
\label{sec:testing}
% ##################################################
% LAST EDIT:  28/03/17  JOSH
% NOTE:       Draft v2
% ################# Comment Log ####################
% 
% ##################################################

% ################# References #####################
% Types of Extreme Programming Testing:
% http://fileadmin.cs.lth.se/cs/education/EDA270/Reports/2009/SvenssonGraden.pdf  -- Academic paper on testing in extreme programming

% Test Driven Development:
% Software Engineering Course Textbook Section 8.2 -- This textbook: https://www.amazon.co.uk/Software-Engineering-Ian-Sommerville/dp/0137053460/ref=sr_1_2?ie=UTF8&qid=1490812405&sr=8-2&keywords=software+engineering+sommerville
% http://agiledata.org/essays/tdd.html -- Software engineering blog on test driven development with further textbook references

% Continuous Integration:
% https://www.martinfowler.com/articles/continuousIntegration.html  -- Fowler referenced a lot by Tim
% http://aosabook.org/en/integration.html  -- Further reading link on continuous integration for PSD Moodle page
% ##################################################

Thorough testing of any large-scale software project is a fundamental part of the development process. Best practice testing not only helps assure the customer they are receiving as inerrant a system as possible, but allows us as developers to detect issues earlier in the process, reducing the cost of correcting faults than if they were discovered further on in the development \cite{SoftwareEconomics}. 

On our project, testing was \textit{crucial} to enforce consistent interface usage amongst classes and functions implementing different recommenders. When rapid or concurrent changes are made to our project components, our test suite instantly notifies the entire development team, informing them of a broken or faulty build. \textit{Software testing in Extreme Programming} \cite{SoftwareTesting} suggests unit testing, integration testing, system testing and acceptance testing as the four most critical ways in which components of a system can be tested. 

Recognising the importance of the test process, the team made the decision at the mid-point of the project to dedicate the majority of one developer's efforts solely to the process of testing the system and building the relevant regression and integration test modules. We outline our rationale for assigning one developer to this task in Section \ref{sec:teamstructure}. We discussed whether a test-driven development (TDD) strategy would be appropriate to our project. TDD involves writing tests before writing code to pass those tests \cite{TDD}. The team decided not to pursue this strategy as due to the research-based nature of the system, the project structure, class definitions and method signatures would change significantly throughout the development cycle. 

Initially the testing comprised the creation of suite of unit tests to ensure each alteration to the source code did not break the execution and build of the system. Due to the simultaneous development of multiple system components, the test suite was helpful in signalling issues when an interface was broken or expected functionality was non-performant. In particular, in the latter phases of the project when concurrent work was occurring on multiple recommenders, issues often surfaced when their outputs were merged into the System recommender. These problems were flagged by the test suite, enabling team members to patch broken builds efficiently and continue development. Integration testing was performed by running the System recommender in conjunction with the other recommenders. In addition, the unit tests also served as regression tests, ensuring that existing functionality did not fail when adjustments were made after integration.

Acceptance testing was conducted throughout the development process during frequent meetings with the customer. This involved displaying arbitrary diners, selected at random, with their recent bookings and our generated recommendations side-by-side. This provided an intuitive way for the customer to assess whether the output was sensible, and whether it matched the behaviour outlined in the user stories agreed at the outset of the project.

The test suite for the project was set up to run on Jenkins, a continuous integration environment. Automatic test cases were scheduled to run after each commit to the project's source code and in the event of failure the team would be immediately notified of a broken build. This allowed early detection of defects. In addition, Jenkins was configured to provide coverage reports for the source files, indicating the proportion of the project covered by test cases. This was established through the Cobertura extension to Jenkins,  providing a detailed visual representation of the coverage reports, indicating the percentage of classes, conditionals and lines covered. This feedback was used identify which portions of the source code were in further need of testing.

Nonetheless, as with all elements of our project and process, there are opportunities for improvement. Although the testing followed the general principles of the Extreme Programming test methodology, the lack of any particular strategy lead to the discovery of missing test cases in several modules. By following a stricter, more systematic test plan these issues may have been mitigated. One particular omitted type of testing which the team would like to have incorporated is mutation testing. Mutation testing introduces small faults to software code, and evaluates whether or not the existing test cases “capture” those mutations. In this way, it helps to verify the quality of the test suite.

Additionally, the inclusion of stress testing to analyse the performance of the engine as it processed varying sizes of data would have been useful. In practice, however, we found that such tests would be difficult to perform due to the direct dependency of the project on Apache Spark. This was primarily due to the potential speed of computing recommendations being maximised through alteration of the configuration of Spark to use multiple cores.  

The final area for improvement would be to incorporate statistical measures into the testing process. Machine learning is heavily reliant on statistical metrics (such as Root Mean Square Error (RMSE)), and assessing the quality of the output requires analysing same. Of all the potential tests considered for the project, however, this was identified as being the most difficult. The decision was made to rely on the system’s own evaluation component to provide statistical assurance of the quality and accuracy of the recommendations, while the testing would focus on the functionality. Ultimately this approach proved quite successful as the team produced both an accurate recommendation system and a well-tested system.


\subsection{Reflection: Team Structure}
\label{sec:teamstructure}
% ##################################################
% LAST EDIT:  28/03/17 JOSH
% NOTE:       First Draft
% ################# Comment Log ####################
% REFERENCE: Role based model for team structure - Formerly called "Sports" which I believe to be a Tim term
% ##################################################

% ################# References #####################

% Developer Anarchy: 
% https://www.youtube.com/watch?v=uk-CF7klLdA  -- Fred George on Developer Anarchy Talk (his name seems to crop up here is a talk)
% https://martinjeeblog.com/2012/11/20/what-is-programmer-anarchy-and-does-it-have-a-future/  -- Software Engineering blog on developer anarchy

% Decided to use developer anarchy, popularised by Fred George...

% Role Based Structure:
% http://www.ambysoft.com/essays/agileRoles.html -- Software Engineering blog on use of roles in development teams of varying sizes - referencing 'experts' as you have

% Textbooks:
% The Mythical Man-Month Book
% ##################################################
Large-scale software development requires effective team organisation. Managing six developers and ensuring everyone was able to contribute to the project was an ongoing challenge, which resulted in us experimenting with several team structures.

Initially the team elected to use a `programmer anarchy' team structure - where individual team members are free to select a task they’re currently interested in working on and pursue it \cite{ProgrammerAnarchy}. While an unconventional structure, we felt confident in our ability to communicate and organise development resources. All members of the team were comfortable with the concept of working on both the back-end and front-end functionality as needed. Finally, as the proposed system design allowed for concurrent development in different recommenders, we believed the anarchy development style was suitable fit for the project. 

In practice, however, problems soon emerged. The team was generally optimistic following the December 8th retrospective that natural roles for some members had fallen into place. But we all felt that better project organisation was needed and more effective and open communication on what different developers were working was essential. For example: task allocation did not actively reflect what developers were working on. While actions were taken to rectify these issues (discussed in the next section), at the following retrospective on January 26th, the same problems were again apparent. 

Furthermore, some team members began to feel underutilised and it was noted at this point that components of the system - the front-end, testing and content-based recommendations - had not been given sufficient attention. Fred Brooks' well-known software book \textit{The Mythical Man-Month} warns of the danger of dedicating too many development resources to one task without any increase in productivity (Brook’s Law) \cite{ManMonth}. We were focusing all our effort on developing the ALS recommender, when in reality only two developers were required. As Brooks’ humorously suggests, “The bearing of a child takes nine months, no matter how many women are assigned.”

%I can’t find any references to this sport model 
%		- Its in the Lecture 6 slides though I'm guessing its a Tim created term for a role based system 
To combat this inappropriate resource allocation, the decision was taken to alter the team structure and give individual developers more formal, well-defined roles. The team split into two separate development sub-teams: one continued building the recommendation engine, and the other was tasked with construction a front-end display application. Each team member was given a clearly-defined role. 

Embracing this model saw the productivity of the team vastly increase by ensuring tasks were fairly allocated, and enforcing a more sensible work-flow. Team members were able to develop expertise in their part of the system while having general appreciation for the overall architecture (`generalising specialists' \cite{AgileRoles}). Having “experts” proved invaluable when developers encountered an unfamiliar part of the software. This was extremely beneficial when it came to testing, for example. The lead test developer was able to leverage expertise from other developers on their specific aspects of the system. Rapid responses to their queries allowed us to reduce the time required to implement test cases. Additionally, the lead developer for the component could provide feedback to the tester on how improvements and further tests.

Through experimentation with the team structure, we eventually found a system we were comfortable with, allowing development to occur at a steady pace. We discovered that development flows that looked good “on paper” (developers all working on the recommenders) did not work in practice, and gained experience in identifying problems, reshaping a team and rectifying issues before they derailed a project. 

\subsection{Reflection: Team Communication \& Issue Tracking}
\label{sec:communication}
% ##################################################
% LAST EDIT:  28/03/17  Josh
% NOTE:       v2
% ################# Comment Log ####################
% Here I'm just trying to sum up some of the communication issues and suggest some ways of rectifying them

% Maybe it would be best to go more into detail on what improvements did occur but I don't know what that
% would be beyond "You we talked to each other more"

% Suggests the use of quick stand up style meetings and burn down charts as an easy fix to the problems faced

% Josh: Rationalised this, possible candidate to be merged with Team Structure section with issue tracking specifically moved elsewhere?
% ##################################################

% ################# References #####################
% Stand ups:
% https://www.martinfowler.com/articles/itsNotJustStandingUp.html  -- Martin Fowler (him again) guide to stand ups
% http://www.scrumguides.org/scrum-guide.html#events-daily  -- Scrum Guide on Daily Stand Ups
% https://www.mountaingoatsoftware.com/agile/scrum/meetings/daily-scrum  -- Another SE blog on stand ups
% https://www.agilealliance.org/glossary/daily-meeting/  -- Another SE blog on stand ups

% Burn down charts:
% https://www.scrumalliance.org/community/articles/2013/august/burn-down-chart-%E2%80%93-an-effective-planning-and-tracki  -- SE blog on burn down charts
% http://www.agilenutshell.com/burndown  -- SE blog on burn down charts
% ##################################################

As part of our Agile development process; the team conducted retrospectives at the end of each Sprint. In each retrospective session we would discuss aspects of the iteration that went well and areas we could improve. Throughout the retrospectives; an issue that was consistently highlighted was that of communication between developers.

During the first retrospective, we identified that there was a lack of a dedicated communication channel for development issues, resulting in project information being lost between team members. The decision was promptly made to use team communication software (Slack) for development discussion. In addition, we noted that only a subset of developers were actively using the ticket management system (TRAC). Thus, efforts were made to ensure all team members were using the issue management in a consistent manner. We introduced team-wide style guidelines for commit messages to enforce this. 

Initially, even with these remedies, some communication concerns persisted. There was a lack of active communication on the Slack channel and a slow response rate to following through on assigned development tasks in the tickets. Fortunately, by the final development sprint, the team had addressed these issues and was communicating consistently. The team restructuring discussed in the previous section \ref{sec:teamstructure}, the use of pair programming (outlined in Section \ref{sec:pairprogramming}) and more active participation on the Slack channel saw an increase in the frequency and quality of communication between developers. Nonetheless measures could be taken to improve on future projects.

The team met regularly during development to discuss progress, but the meetings were generally unstructured and at different times each week. Agile development methodologies such as Scrum often include a daily stand up meetings. Stand-ups are brief, focused team discussions where progress accomplishments are laid out, obstacles to development are discussed and the next development tasks towards to end sprint goal are clarified. While conducting daily meetings was impractical for our project, having a more formal structure to our weekly meet-ups would have eliminated uncertainty on what other developers were working on and helped enforce responsibility. 

Additional practices we could have undertaken include the utilisation of burn-down charts and code reviews (discussed in the next section). Burn-down charts provide a visual indication of the team’s progress towards the end sprint goals. This would have helped address the issue of TRAC tickets being highlighted as actively worked on, but their completion not being seen to in timely manner and helped clarify which tasks needed to be prioritised or required more resources to be assigned. 


\subsection{Reflection: Code Reviews \& Branching}
\label{sec:codereviewbranch}
% ##################################################
% LAST EDIT:  30/03/2017 JOSH 
% NOTE:       v2
% ################# Comment Log ####################
% Very, very, rough
% Struggling to explain why it appeared that commits were fine which were in fact broken
% REFERENCE: Good Agile code commit practices
% JOSH: I've done my best to explain it here. 
% ##################################################

% ################# References #####################

% Blogs on pre-merge code reviews:
% http://verraes.net/2013/10/pre-merge-code-reviews/
% http://haacked.com/archive/2013/10/28/code-review-like-you-mean-it.aspx/
% https://about.gitlab.com/2015/08/05/6-reasons-why-pre-is-better-than-post-production-code-review/
% https://thepugautomatic.com/2014/02/code-review/

% Coding Horror on Code Reviews:
% https://blog.codinghorror.com/code-reviews-just-do-it/

% * Case Studies on Code Reviews:
% https://smartbear.com/SmartBear/media/pdfs/best-kept-secrets-of-peer-code-review.pdf

% Textbooks:
% Code Complete - benefits of code reviews
% Software Engineering Recommended Course Textbook - Chapter 24  -- Code Reviews Chapter
% ##################################################
From the outset, recognising the importance that system design would have on the outcome of project, the proposed design was constructed to achieve high levels of cohesion and low levels of coupling between components. As we outline in Section \ref{sec:modelreflection}, the system consists of multiple recommenders, a system recommender and an evaluator. The team determined that these components were sufficiently independent to allow development to proceed without the need for development trunks. We felt that adopting a branch-heavy mentality would discourage committing code due to the additional time required to handle merge costs, and would decrease the rate of code re-factoring. Although this system of minimising branching did ensure prompt integration of code throughout the duration of the project, it was not without its problems - particularly during the latter stages of development.

As the development of the system progressed and the complexity of the software increased, the integration of new code became an issue. We noted during the fourth retrospective, new code would be added to a particular recommender, which would break the system evaluator component. Occasionally, code would also be committed which was unfinished and being refined. Obviously, this is not good Agile practice though a potential mitigation is that our integration tests were not set up to catch errors with the evaluation component. The tests correctly checked that recommenders were generating recommendations but not whether or not they were functioning with the evaluator. Nonetheless, as a result of poor communication between developers \ref{sec:communication}, this would sometimes lead to another developer's work being deleted in order to fix the broken build. Clearly, this is a suboptimal work-flow and results in conflicts and confusion. 

To combat this issue, the team agreed following the fourth retrospective that we would discuss modifications to other developer's code before modifying it. Furthermore, we agreed that we would refrain from submitting non-functioning code. These methods were suggested due time restrictions as the work entered the final development stage. The proposed solutions did largely address the issue in the last iteration. However, we recognise that such ad-hoc practices are, at best, short-term solutions. A long term, formal and professional approach to reviewing other team member's code and managing commits is desirable and would've helped avoid many of the issues we encountered.

The standard industry approach to avoiding such internal conflicts is through the use of code inspections and code reviews. Steve McConnell suggests in his handbook on software engineering, \textit{Code Complete}, that ``the average defect detection rate is only 25 percent for unit testing, 35 percent for function testing, and 45 percent for integration testing''\cite{CodeComplete}. By contrast, design and code inspections discover over 50 percent of code defects. This suggests that regardless of test strategy, the most effective method of ensuring proper integration would be to conduct the code review process. Although some measure of code review was attempted through the use of pair programming (discussed in the next section), a more comprehensive approach would have been to introduce pre-merge or post-merge code reviews to the project. Adoption of pre-merge reviews in particular would have flagged integration defects and issues earlier and avoided the need to delete code from the master branch in order to fix the build, as was highlighted previously when discussing the issues with integration with the evaluation system. The methodology instead would be for major development work on a particular recommender to occur on its own branch. Prior to integration with the master branch a pre-merge code review would be conducted. This would have highlighted merge conflicts and defects in the code earlier and thus avoided the need for team members to modify one another's code. Pre-merge code reviews would also have had the benefit of increasing knowledge of how all components fit together and would have facilitated better shared practices within the team, for example: a more consistent code style. It may have also reduced the need for some re-factoring.

In retrospect, the team discovered the benefits and need for code reviews first hand. Although we effectively coped with the situation, our mechanisms would not suffice over the long term. The problems which arose from not conducting pre or post merge code reviews demand thoughtful, best-practice and professional solutions. In \textit{The best kept secrets of code review}, the authors discuss the impact of code review on the outcome of a project \cite{CodeReview}. They found by tracking the bug fixing in a 10,000-line project over six months and then asking another group of developers to peer review the code, 150,000 dollars would've been saved by conducting code reviews. Clearly, the impact of not conducting code reviews can be ruinous for a software project. 

Ultimately the decision to avoid branching was the main determinant in not utilising code reviews. As we demonstrate, a looser approach to coordinating commits can function adequately in the initial stages of development. But as the code base complexity and interaction between components grows so too does the need for a more organised approach. Had the team recognised this earlier, then the code review process could have been introduced alongside the pair programming process at the start of the fourth development milestone.   

\subsection{Reflection: Pair Programming}
\label{sec:pairprogramming}
% ##################################################
% LAST EDIT:  28/03/17  Josh
% NOTE:         v2
% ################# Comment Log ####################
% ##################################################

% ################# References #####################

% Papers:
% https://collaboration.csc.ncsu.edu/laurie/Papers/XPSardinia.PDF

% Journals:
% https://accu.org/index.php/journals/1395

% Blogs:
% https://www.agilealliance.org/glossary/pairing/
% http://www.extremeprogramming.org/rules/pair.html
% ##################################################

Pair programming is an Agile development practice where two programmers work at a single computer. One developer takes the role of \textit{driver} and actively writes the code, the other takes the role of \textit{navigator} and reviews the code. Roles are ideally switched at regular intervals. The primary benefit of pair programming is that the navigator is able to check the driver’s code for mistakes and inefficiencies in real-time. At a modest cost to development time (15\%), pair programming can enhance the quality of the sofware design, reduce software defects and improve communication between developers \cite{PairProgramming}.

The team had gained some basic experience with the practice whilst participating in the University of Glasgow second year Java development course. We wished to observe how the practice translated to a larger and more complex `real world’ project - beyond the artificial nature of an academic task within a laboratory setting. An opportunity arose to make use of pair programming after we divided the project into sub-teams for the third iteration.

The team made the decision to build a front-end display application to help the customer better visualise the generated recommendations. Two members of the sub-team responsible for handling the display application worked as a pair during the design process. We decided to treat the initial front-end as a throwaway prototype and incorporate the feedback and observations into a brand new design. Initially, this began with the developers meeting to create GUI mockups for the proposed front-end. One developer sat at the computer creating layout screens (using Moqups prototyping software), while the other reviewed and offered suggestions. Both developers were actively communicating throughout the session. The next session involved creating the front-end demo using HTML, CSS and Node.js.

Our experience of pair programming chimed with the advantages suggested in the literature. We reduced the coordination effort required between team members and ensured both developers knew the entire extent of the development work, including the specifics of the system, upon completion of the exercise. This allowed for more efficient individual development, as both developers had created the foundation of the application and discussed where their efforts would be focused next.

Additionally, as the developers had differing levels of prior experience (one developer had professional experience), pair programming facilitated increased diffusion in knowledge among team members, reducing the potential for defects and poor design decisions. While pair programming should not be thought of as a student-mentor relationship, the less experienced web developer benefited from picking up on the minute techniques and broader skills used by the more experienced developer.

Ultimately, although the technique was used occasionally for debugging aspects of the display application and recommendation engine, the process as highlighted above was only conducted thoroughly once during the development cycle. Having observed the benefits suggested by proponents of pair programming, both the developers who undertook the exercise and the team as a whole expressed regret that the practice was not used more frequently during development. Were the team to have an opportunity to work on a future project, pair programming would be encouraged earlier and more often.

\subsection{Reflection Point - Dropping Features}
\label{sec:droppingreflection}
% ##################################################
% LAST EDIT: 30/03/17 JOSH
% ################# Comment Log ####################
% ##################################################
% Josh: Merged cost estimation material into this 
% ################# References #####################
%
% Academic Blog:
% http://www.umsl.edu/~sauterv/analysis/6840_f03_papers/gurlen/
%
% Paper:
% http://searchdl.org/public/book_series/AETS/2/174.pdf
% http://research.ijcaonline.org/volume106/number2/pxc3899533.pdf  -- Case study style of paper (team knew of well established dangers)
%
% ##################################################

There are many reasons that a proposed feature may be removed from the development schedule of a software project. Customers can change their minds, time constraints may force a rationalisation of goals for an iteration and technical challenges may impede the completion of a feature. Over the course of our project, features were proposed and dropped for all three of these reasons. We also dropped features to ensure we remained focused on delivering the project's main goals and not get distracted by delivering ancillary functionality. We note, however, that none of the features we decided to drop were indulgent or without utility to the customer. They were often based on suggestions made by the customers at our meetings. Indeed, we suggest that some would make excellent future additions to the software. Nonetheless, it's useful to analyse the reasons why certain features were dropped for this version, and whether an alternative approach to time management and cost estimation might have enabled us to deliver some of them.

One of the team's initial ideas was to try to provide recommendations for new ResDiary users upon sign-up. The data required to build their profile would be collected in the form of a questionnaire, filled out after registration. While the proposal seemed to make sense at the start of development, it became clear that implementing the feature would not only consume a significant amount of development resources, but would stray from the customer's vision. The team discovered during some initial low cost prototyping and research that generating recommendations for new users would most likely be based off a search or filter system, not a similarity between users (delivering a working collaborative filtering model was our key focus at this stage). Further, new users are unlikely to fill out questionnaires and thus the data required to make any sort of meaningful tailored suggestion would most likely not be available. The feature was formally dropped after the third sprint.

Avoiding unnecessary developer `gold-plating' was not the key reason features were discarded. More generally, we dropped features to avoid the prospect of feature creep - often identified as a key reason software projects end in ruins \cite{ProjectFailure}. While our initial requirements gathering was thorough, and we took care to avoid under-scoping the project, it is inevitable that new features will be imagined as development proceeds and the problem domain becomes more well-understood. 

An example of an emergent feature was the idea of providing some rationale, or metric that would enable a user to reason about why given recommendations were made. The feature would've stated which individual recommenders contributed most heavily to the final restaurant suggestions produced by the system recommender. Despite keen interest on the part of the customer to see this feature realised, and the team's desire to incorporate it, it was ultimately found to be too large a task to implement. The idea was suggested by the customer towards the latter stage of the development process. We determined there was insufficient time to meaningfully implement the addition, and the remaining development was best spent on core functionality: refining the generated recommendations and refactoring. Another feature that was suggested was providing Google Map integration on the front-end, so that we could visualise where suggested restaurants were relative to restaurants a user had visited. Again, while a welcome addition, we decided our resources were best allocated on the more fundamental tasks.

The lack of formal cost estimation techniques may have contributed to not being able to deliver some of these features. While the team agreed through informal discussions which tasks took highest priority, we believe that the use of a cost estimation technique (such as planning poker) in each sprint would have allowed more accurate time and cost estimates for each task. This would have allowed us to give a better estimate of the workload each developer was assigned and identified if resources were available for completing the candidate tasks. These measures would've been particularly useful in the second and third sprint where some developers were feeling underutilised. 

Ultimately, though the team had to drop certain features, we learned to identify scope creep and responded positively by taking corrective action. We were able to justify to the customer at each meeting why certain features had been dropped or de-prioritised. The successful outcome of the project, in terms of delivering almost all of the core, agreed functionality is a result of not wasting valuable development time on tasks outwith those goals. 


%\subsection{REFLECTION POINT - Cost Estimation and Task Backlog}
%\label{sec:costreflection}
% ##################################################
% LAST EDIT:  26/03/17  Joseph
% NOTE:         Temp notes / thoughts
% NOTE:    JOSH: Going to remove this and move points to other reflections. 
% ################# Comment Log ####################
% I have no real idea where I'm going with this section
% ##################################################

% ################# References #####################
% Cost Estimation:
% Chapter 23 - Software Engineering Textbook Recommended in Course
% https://www.martinfowler.com/bliki/PurposeOfEstimation.html  -- Martin Fowler Purpose of Estimation
%
% Planning Poker:
% https://wingman-sw.com/articles/planning-poker
% https://www.mountaingoatsoftware.com/agile/planning-poker
% ##################################################

% Talk about why cost estimation is good for a project
%Cost estimation...

% I have no idea how to lead into this topic
%Refelecting over their time on the project the team believes that the lack of formal cost estimation techniques had a determentally effect on the project. (Reference all the reflection subsections where I've off loaded cost estimation as an issue and area for improvement). Rather than use a formal cost estimation method, as is outlined below, the team instead chose to simply establish a common understanding of which tasks per sprint should be prioritised for completion and which would require the most developer resources to complete. While such as system did see the completion of the most important tasks per sprint it also saw the several tasks be put on backlog and ignored and thus pushed to into the next development sprint. 

% Get across the idea that planning poker would have solved issues
%To combat such behaviour the use of a cost estimation technique, such as planning poker (reference to planning poker), each sprint would have better highlighted the cost and time estimates for each task per development sprint. This would have given a better estimate of the workload assigned to each developer and highlighted potential situations where one developer had committed to a greater amount of work than was feasilbe for a particular sprint. This would have allowed other developers to step and and reduce over committed developers workload and thus increased the throughput of completed tasks per sprint. Additionally planning poker would have assisted and encouraged the creation of the burn down charts as proposed for use in Section (reference communication section) which would have aided the team's task management and thus benefitted the team in multiple development channels. Had such techniques been introduced from the outset of the project then the development time may have been found to include dropped feature of generating reasons for recommendations as is discussed in Section (reference dropped feature section) as the team would have been better prepared to manage the finite free development resources available towards the end of the development cylce and found the needed resources to develop the feature for inclusion within the final system. 


% HERE DOWNWARDS ARE MISC NOTES
% Requirements Engineering:
% (Lecture 13) Requirements gathering is an ongoing iterative process that runs concurrently alongside requirements analysis and capture - our project saw this in real effect due to the changing nature of the requirements of our project.
% (Lecture 14) Requirements engineering is an iterative process of elicitation, capture and validation - talk about how we did this to ensure we were gathering the correct requirements.
% (Lecture 3) Causes of software project failing - building system for wrong reason, building the wrong system, building the system wrong. We could tie in the dropped new user recommendation to a proposed goal which was later determined to be a requirement which would be built for the wrong reason. As such the feature was dropped to avoid building an incorrect system.
% (Lecture 13) Cultural differences between engineers and customers - although the developers were technical they don’t know anything regarding machine learning or the development of a system such as ours - Requirements Risk
% (Lecture 13) Vague requirements specification of end state of system / customer uncertainty regarding the final state of the system - Requirements Risk
% (Lecture 13) A means of investigating poorly understood requirements (prototyping) - Managing Requirements Risk - perhaps we could have prototyped both a front end display and an integration method / discussed this with the customer earlier. This would have defined a determined end state of the system prior to January which would have allowed for an earlier split in development focus and resulted in either integration or improved front end. Granted one must also consider that technical decisions were still ongoing at this time.
% (Lecture 13) Requirements evolution - occurred when we discovered potential features which were ultimately dropped (new user recommendations)
% (Lecture 14) Avoid early commitments to particular design solutions during requirements elicitation

% Communication:
% Slack was set up and made the dedicated communication channel for project communication.
% Despite having a Slack communication remained somewhat poor.
% Decision made to ensure tickets actively represent what feature of the system you are working on.
% Ticket system improved but commits / development did not occur in a time efficient manner.
% Sub teams additionally helped communication within front end and back end through team communication as a whole was still somewhat lacking.
% Specific incident - Edward not providing data sent from customer in a timely manner.
% Part of team felt agreeing to meet up in person at least once a week to work on project was a waste of time / resources - this had an adverse effect on communication that wasn’t addressed. Instead majority of team met up once a week at scheduled time as some developers strayed through the valley of the shadow of death into the unknown.
% Perhaps Joseph focusing less on development taking on a purer scrum master of role would have improved the development though it due to this being an academic project that the team felt that not suitable or possible as everyone should have played an active role in development.
% Talk about the benefits a product owner would have had on the development of our specific project - improved efficiency of tackling task backlog (tasks were avoided from one milestone to the next)
% (Lecture 7) Perhaps burn down charts per sprints would have been a good idea and would have improved prediction of task completion, backlog management, communication and prioritisation of backlog tasks.
% Pair programming increase communication and coordination greatly - positive
% Subteams increased communication a lot as well - postive

% Code Reviews:
% The system was designed such that branching was unnecessary for the project. Branching was somewhat discouraged throughout the project in order to reduce merge costs / time. Whether the time saved outweighs the time spent fixing and altering other people’s code remains to be seen.
% Lack of code reviews meant that the code often had inconsistent styling.
% Lack of code reviews meant a significant portion of time was spent fixing or altering other people's code to work with parts of the system they did not realise they had broken.
% Lack of code reviews meant code which was WIP was deleted prior to it being fully implemented into the system - again lack of branching issue somewhat.
% Suggested at the first retrospective but ended up avoiding. Would have reduced a number of problems with development cycle but you can't be perfect.
% Highlighted in retrospective 3 with the code integration being highlighted.
% Highlighted even more in retrospective 4 with code integration really being highlighted.
% Reference potential methods or strategies for code reviews which could have integrated into the development.
% Reference how other and often professional developers recommend doing code reviews.
% Mention that pair programming was conducted and the benefits of doing it. Mention it should have been conducted more frequently, reference that it was beneficial when suggesting if XP was potentially better than Scrum.
% Code reviews might have improved development efficency as less time spent refactoring and fixing broken code. Reduced arguments caused due to deleting other people's code prior to full implementation. Branching also would have fixed this as only get back to master upon passing all tests. This would require testing to have been more efficent as well thus suggesting test strategy should have been utilised to improve test efficency.
% (Lecture 26) Outline of inspection methods - should probably mention which we should have used in the code reviews.
% (Lecture 8) Change management and the conflicts caused from developers working in parallel and contributions are made to the master branch which are not fully implemented or break some aspect of the system. In hindsight this probably should have justified a separate branch which would be integrated into the master upon passing all of the tests with a successful build in Jenkins the continuous integration system.

% Cost Estimation:
% This comes up a lot and should be its own reflection point
% Discuss that it was not properly conducted and explain the benefits of employing it
% Talk potential cost estimation techniques we could have employed (planning poker)
% Discuss what other developers advocate in this regard and how they could have been incorporated into our project

% Misc:
% (Lecture 19) Throw-away front end prototype was used and was good as it gave a better understanding of the requirements the front end would require upon it becoming the final state of the system. This knowledge and the discovered failures fed into the redesigned system and so the throw-away prototype was very beneficial to the project. (MINI REFLECTION POINT ?)
% (Lecture 19) Prototyping is used to reduce risks caused by uncertainty in software projects, not introduce more risk - to some extent this was done for components of the back end system as well.
% (Lecture 30) Formal specification is a specific thing so probably don't just refer to a specification document as being formal loosely.
% (Lecture 32) Refactoring is an important process which went on over the course of development.


% -- OLD TECHNICAL LEAD IN SECTION --
% This section should be a mainly postive reflection of the technical choices of the project.

% The occasional limitation can be mentioned in the passing such as the use of Python scaring the customer off integration (theory) 
% and the drawbacks of the collab not allowing for training based on only new data (this if anything is a requirements engineering failure
% that could have been picked up earlier but customer did not consider until after seeing operation of prototype and use of data in its creation)
% Spark was fine. I have no gripes about using Spark.

% 1. Talk about why the technical choices are significant development points in the software development process.
% 2. Talk about how preemptive commitment too early is bad and should be avoided - reference case study - saying team used this as an warning. Use this as reference throw over to requirements engineering reflection point. 
% 3. Introduce the three major technical decisions of our project
% 4. Tie in testing and use as a reference throw over

% Preemptive commitment to particular design choices too early in the software development cycle leaves a software project at high risk of failure (reference a case study where an incorrect design decision lead to failure - lecture 1 / 3 recommended reading?). Summary of how this system failed in relation to incorrect design choice. 

% Say the team used this as a warning for the major design decisions - Development language, Models, Spark - that were involved with our project which are detailed below.

% State how the technical choices do not occur in isolation rather they are heavily work with the requirements gathering stage (reference lead in)

% Additionally discuss how they are related to the testing of the system (reference lead in) 
 
% However the technical choices of a software project are not made in isolation rather they are heavily influenced by the requirements engineering process of the 


% -- OLD SCRUM LEAD IN SECTION --
% Lead in with a general why Agile is used for large projects such as ours.
 
% As is often a common practice in industry (get a reference backing up claim) the team did not adhere strictly to one specfic agile framework. Instead the Scrum methodology was used as the overarching framework with additional agile practices from alternative methods, such as prototyping and extreme programming, being adopted as the team felt their use necessary and applicable. While this behaviour ensuresd a flexibile production envirnoment and the team found modertate success with the loose methodology it was not without its issues. Primarily this was due to the lack of discipline within the team to hold all of the key Scrum methods, as weekly stand up style meetings were cancelled in favour of a more open source style of development environment, and roles, as the team employed no product owner role and the scrum master was additionally on the development team. 

% Ultimately this would come at a cost of the teams ability to collaborate effectively on the project as the lack of stand ups led to communication issues as is discussed in Section (reference communication issue). Additionally the lack of product owner and focused scrum master roles played into some disfunctionality within the team organisation structure as highlighted in Section (reference team structure). By not conducting incomplete work and priority reviews at the each sprint's end the team inevitably saw proposed features be dropped as is discussed in Section (reference dropping features) and examined more thoroughly in Section (reference backlog management). This however may also be a consequence of the lack of formal cost estimation procedures conducted during the project as examined in Section (reference cost estimation) and not the teams approach to the Scrum methodology. Finally the issue of if whether such failures could have been avoided through use of a different agile framework, the Extreme Programming framework, is considered in comparision to following the Scrum methodology more strictly and closely than was conducted by the team in Section (reference stricter Scrum vs XP - final reflection point).


% -- I don't know if the requirements engineering section is needed or entirely relevant (certainly saves word count) --
% -- At this point its all just words to me anyway --

% \subsection{REFLECTION POINT - Requirements Engineering}
% \label{sec:teamstructure}
% ##################################################
% LAST EDIT:  20/03/17  Joseph
% NOTE:       First Draft
% ################# Comment Log ####################
% - References the cost estimation reflection point as an improvement - tie those two together
% - References scenarios which flows to testing via test scenarios / acceptance testing - ties those two together
% Reference back in subsequent reflection points to reduce lead in repetition 
% ##################################################

% Perhaps tie in the requirements risks and perhaps suggest methods of dealing with such risks via papers

% Basically we've reflected on the technical choices now why was it important that the requirements were engineering properly to better inform the technical choices and what could have been done to do this process even better

% From the outset of the project the team were aware of the need to properly capture the requirements of the project. It is widely documented that two of the primary reasons for software failure is due to building the wrong system and building the system incorrectly (said in lecture 3 - get academic proof) both of which were major threats to the development of our project. The team was mindful of how easily building an incorrect system, one not based off similarity between users, or selection of the incorrect machine learning model and subsequent project failure could occur in our project. 

% Adhering to the advice of avoiding early commitment to a particular design solution during the requirements elicitation process as is discussed in Section (reference case study reflection at technical overview point) the team left the decision regarding the specific models and tool choice until after this phase was conducted. Although the requirements would evolve as the project developed, as is to be expected, the team felt with the correct initial system goals established the team could easily justify decision designs in relation to the key goals of the system. Such technical decisions, specifically the choice of development language, machine learning models and clustered computing framework, are discussed in Sections (reference all three technical reflections) respectively. 

% Knowing the significance of the requirements engineering process for the sucessful development of the project, the team dedicated the first milestone to ensuring the proposed system to be built was correct. This occurred in parallel with technical research into similar systems and their creation (reference Netflix research from section 2). To ensure the team captured all functionality of the system the team, having conducted the initial customer interview, prepared a requirements specification document which was later refined through customer discussions (reference section 2 requirements section). 

% Within this document the team elected to use the user stories method of requirements specification in order to create an all encompassing set of stories which reflected the proposed features and functionality of the system. As the recommendations are made to ResDiary customers the team felt user stories provided a good a boundary artifact between the proposed users, customers and developers (taken from PSD lecture 15 key point) and that user stories were a natural choice opposed to alternative specification techniques such as use case diagrams because… 
% Try to sell the idea that user stories are the natural choice for our project as user stories are written from the customer perspective and the recommendations are being made to the end customers

% Although some modifications were necessary, as is to be expected, the team found that proposed the user stories modelled the customer requirements with a good level of accuracy (reference section 2 refinements after initial meeting). In addition to this the additional proposed features, generating recommendations for new users and the ability to recommend previously visted restraunts, that the team suggested were recieved with good feedback by the customer. They believed such features tackled aspects of the problem they themselves had not yet considered and felt we had a good understanding of the system. 

% Establish that task estimation was not properly conducted then reference away to specific reflection into that topic
% One shortcoming of the use of stories however was the measure of priority attached to each user stories and the subsequent task breakdown by association. The team did not conduct a formal task estimation procedure beyond the breakdown of the user stories into smaller, more general tasks. This was in part due to the lack of technical knowledge into the subject area from the team at this stage in development though the team should have conducted proper task estimation to assist with project planning and management as is discussed here (reference planning and cost estimation reflection point). 

% Transision into this better and potentially expand on
% Another area of improvement in the requirement gathering process would have been the inclusion of use scenarios in the “Given, When, Then” format. This is a natural progression of user stories as it expands upon an individual story to provide an example of it in action. Such scenarios could then be utilised to allow for further refinement discussions to occur with the customer in order to better establish conditions for system acceptance which would improve the acceptance tests of the system and allow for scenario testing to be conducted on our system. A discussion regarding such tests and other methods of improvements is discussed in Section (reference testing)  

% Tidy up the ending better - more postive - team did well in this regard and so should end on positive note
% Although the aforementioned could have utilised to improve the team's cost estimation and test process for the project, the team established a good understanding of the customer's vision and corresponding system requirements. This ultimately showed during the various customer demonstrations where by second to last meeting they encouraged to the team to follow where we saw the development of the system going as they were already impressed and pleased with the results. This level of confidence placed in the team we feel showed we had a good initial grasp of the system and thus were able to deliver and take steer the project in the direction we saw it heading towards the later stages of the project. 


%==============================================================================
\section{Conclusion}
\label{sec:conclusions}
% ##################################################
% LAST EDIT: 29/03/17 JOSH
% open to making this more reflective if need be
% ################# Comment Log ####################
% This reads fine and does the job -- Joseph
% ##################################################
The project provided an excellent opportunity for the team to experience working on a large scale development and enhance their professional skills. We gained valuable insight into customer interaction, dealing with changing requirements and working as part of a software team. In addition, the team obtained an enormous amount of knowledge and experience in machine learning frameworks, and utilising different software engineering practices in a realistic scenario. 

As we mention at the outset, the project provided a first opportunity for many of our team members to engage with a real-world customer. During the requirements elicitation phase we learned how to translate high-level business objectives into software proposals. When we were demonstrating the software to the customer, we gained appreciation for the need to prepare presentations which give them an intuitive sense of what a complicated software system is actually outputting. Technical explanations (even to other developers) can be daunting and it’s important that we can clearly demonstrate not only working results, but “sell” the system from a business point of view. Our decision to build a front-end demo, replete with ResDiary branding, helped the customer to visualise the output of the system, and contextualise it as a potential part of their business. Overall, our customer interaction skills have improved greatly as a result of undertaking this project.

The project also reinforced the importance of requirements engineering. Without understanding the requirements of the key stakeholders, and gaining a thorough knowledge of the problem space, \textit{any} project is at risk of software failure. In the absence of the rigorous requirements gathering and analysis, the team could easily have produced software which did not meet the customer’s expectations. Thankfully, by building high-level conceptual models, creating user stories and by prioritising features we were able to synchronise the team’s model of the system with the customer’s vision. 

The work involved in building a machine learning system was challenging and required engaging with unfamiliar concepts and developing using unfamiliar technologies. The successful delivery of the project was contingent on extensive background research on the part of the team. Machine learning was an area of inexperience for most team members, and developing an effective solution required gaining an understanding of the area. All team members made an effort to become informed on the different ways of building recommendation systems. Having been through the process of building one such system, we are now much better equipped to tackle similar tasks in the future. 

Additionally, though the development period was relatively compact compared to many real-world projects, the team encountered the common problem of scope creep. We had the awareness and foresight to recognise occurrences of this, and mitigate them by dropping non-critical features from development. As we note in the previous section, our general task management and communication has room for improvement, but we largely avoided the well-documented phenomenon of ruinous, unnecessary features sucking up large portions of development time and resulting in late (or non-) delivery of a finished system.

The team discovered the flexibility of Agile practices by not strictly following one methodology. While this did result at times in poor cost estimation and communication issues, we have outlined measures that will mitigate these problems in the future. Conducting code reviews is an example of such a measure, and had the team the opportunity to start the project afresh, this practice would certainly have been integrated into our process from the outset. On the other hand, we largely avoided commonly alleged pitfalls of Agile methodologies: namely lack of documentation and inadequate testing. Our test strategy and unit test suite was comprehensive and well-designed, and our system documentation was orderly, with a clear set of style guidelines developed.

In general, team members can reflect on a development process which resulted in a successful end product and facilitated gaining rich insight into machine learning and valuable experience in professional software development. Nonetheless, we have identified opportunities for improvement in both our product and our software process, and concrete actions that can be taken to enhance future development.

%==============================================================================
\newpage
\bibliographystyle{unsrt}
\bibliography{dissertation}
\end{document}
